{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkdgu\\AppData\\Local\\Temp\\ipykernel_3268\\2123551740.py:35: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
      "Human: 내 이름은 Morty야!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
      "Human: 내 이름은 Morty야!\n",
      "AI: 안녕 Morty! 만나서 반가워. 무엇을 도와드릴까요?\n",
      "Human: 나는 평택에 살고 있어!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
      "System: The human introduces themselves as Morty. The AI responds in Korean, greeting Morty and asking how it can help.\n",
      "Human: 나는 평택에 살고 있어!\n",
      "AI: 평택은 한국의 중부에 위치한 도시인 것으로 알고 있어. 평택에서는 무엇을 주로 하시나요? 혹시 무엇을 찾고 계신가요?\n",
      "Human: 내 이름이 뭐야 ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송해요, 제가 실수했네요. 당신의 이름은 Morty라고 알고 있어요. 어떤 도움이 필요하세요, Morty?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# on-the-shelf chain : 일반적인 목적을 가진 chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True,           # 문자열 기반이 아닌, ChatPromptTemplate 에서 사용할 수 있는 형태로 반환\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\"),\n",
    "    # 누가 보냈는지 알수 없는, 예측하기 어려운 메세지의 양과 제한 없는 양의 메세지를 가질 수 있음.\n",
    "    # 그리고, 우리는 그것이 System 메시지인지, Human 메세지인지, AI 메세지인지 알 수 없음.\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 그럼 이제 메모리 정보를 활용하여, 응답을 해줍니다.\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 Morty야!\")\n",
    "chain.predict(question=\"나는 평택에 살고 있어!\")\n",
    "chain.predict(question=\"내 이름이 뭐야 ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
