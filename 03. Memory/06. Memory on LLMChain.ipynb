{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory 를 Chain 에 연결하는 방법과 두 종류의 Chain을 이용해 연결하는 방법을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tkdgu\\AppData\\Local\\Temp\\ipykernel_3884\\3329754772.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(temperature=0.1)\n",
      "C:\\Users\\tkdgu\\AppData\\Local\\Temp\\ipykernel_3884\\3329754772.py:9: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n",
      "C:\\Users\\tkdgu\\AppData\\Local\\Temp\\ipykernel_3884\\3329754772.py:14: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m내 이름은 Morty야!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m나는 평택에 살고 있어!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m내 이름이 뭐야 ?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'죄송합니다, 저는 이름이 없는 인공지능 챗봇입니다.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# on-the-shelf chain : 일반적인 목적을 가진 chain, 즉시 꺼내쓸 수 있도록 미리 만들어 놓은 Chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=80,\n",
    ")\n",
    "\n",
    "# 이렇게 코드를 작성하면, AI에게 메모리 내용을 전달하는 내용이 없기 때문에 AI는 메모리에 접근하지 않을 겁니다.\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(\"{question}\"),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 Morty야!\")\n",
    "chain.predict(question=\"나는 평택에 살고 있어!\")\n",
    "chain.predict(question=\"내 이름이 뭐야 ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: The human introduces themselves as Morty and the AI welcomes them, ready to help. Morty mentions living in Pyeongtaek, a city in Gyeonggi Province. The AI acknowledges Pyeongtaek's reputation for its delicious restaurants and tourist attractions, offering to recommend a place to visit in Pyeongtaek.\\nHuman: 내 이름이 뭐야 ?\\nAI: 죄송합니다, 저는 이름이 없는 인공지능 챗봇입니다.\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
      "\n",
      "    \n",
      "    Human: 내 이름은 Morty야!\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
      "\n",
      "    Human: 내 이름은 Morty야!\n",
      "AI: 안녕 Morty! 만나서 반가워. 어떻게 도와줄까?\n",
      "    Human: 나는 평택에 살고 있어!\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
      "\n",
      "    Human: 내 이름은 Morty야!\n",
      "AI: 안녕 Morty! 만나서 반가워. 어떻게 도와줄까?\n",
      "Human: 나는 평택에 살고 있어!\n",
      "AI: 평택은 정말 멋진 도시야! 어떤 일을 하고 계세요?\n",
      "    Human: 내 이름이 뭐야 ?\n",
      "    You: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너의 이름은 Morty야!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# on-the-shelf chain : 일반적인 목적을 가진 chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key='chat_history'\n",
    ")\n",
    "\n",
    "# Prompt 에 메모리를 위한 공간을 만들어줘야 합니다.\n",
    "template = \"\"\"\n",
    "    너는 사람과 대화하기 위해 AI의 도움을 받아야 해.\n",
    "\n",
    "    {chat_history}\n",
    "    Human: {question}\n",
    "    You: \n",
    "\"\"\"\n",
    "\n",
    "# 그럼 이제 메모리 정보를 활용하여, 응답을 해줍니다.\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"내 이름은 Morty야!\")\n",
    "chain.predict(question=\"나는 평택에 살고 있어!\")\n",
    "chain.predict(question=\"내 이름이 뭐야 ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
