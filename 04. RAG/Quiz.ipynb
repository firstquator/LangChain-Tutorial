{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 1` Why are Prompt Templates usefuls ?\n",
    "\n",
    "- `A1.` They help us give embeddings with variables to the LLM\n",
    "\n",
    "- `A2.` They help us reuse prompts and format them with variables   ( âœ… )\n",
    "\n",
    "- `A3.` They help us compress prompts to save tokens\n",
    "\n",
    "- `A4.` They help us format the responses of the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 2` What is the difference between a PromptTemplate and a ChatPromptTemplate?\n",
    "\n",
    "- `A1.` PromptTemplate is to format chat messages and ChatPromptTemplate is to format a string\n",
    "\n",
    "- `A2.` ChatPromptTemplate is to format chat messages and PromptTemplate is to format a string ( âœ… )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 3` What does LCEL mean?\n",
    "\n",
    "- `A1.` LangChain Express Language\n",
    "\n",
    "- `A2.` LangChain Expression Library \n",
    "\n",
    "- `A3.` LangChain Expression Language ( âœ… )\n",
    "\n",
    "- `A4.` LangChain Extension Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 4` Why do we use few-shot examples?\n",
    "\n",
    "- `A1.` To give examples to LangChain on how to format the prompt\n",
    "\n",
    "- `A2.` To give examples to LangChain on how to format the response\n",
    "\n",
    "- `A3.` To give examples to the LLM on how to format the response ( âœ… )\n",
    "\n",
    "- `A4.` To give examples to the output parser on how to format the response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 5` What does the | operator do here?\n",
    "\n",
    "> prompt | model | output_parser\n",
    "\n",
    "- `A1.` It formats the prompt, sends it to the model and gives the output to the output parser ( âœ… )\n",
    "\n",
    "- `A2.` It calls the output parser, gives it to the llm and uses the formatted prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 6` What does RAG mean?\n",
    "\n",
    "- `A1.` Retrieval Added Generation\n",
    "\n",
    "- `A2.` Robot Augmented Generation\n",
    "\n",
    "- `A3.` Retrieval Augmented Generation ( âœ… ) \n",
    "\n",
    "- `A4.` Retrieval Augmented Guide\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 7` When do we need to do RAG?\n",
    "\n",
    "- `A1.` When we want to use an LLM with data it was not trained with ( âœ… )\n",
    "\n",
    "- `A2.` When we want to use an LLM with data it was trained with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 8` When doing RAG why do we need to split documents?\n",
    "\n",
    "- `A1.` To make the document harder for humans to read.\n",
    "\n",
    "- `A2.` To reduce the word count and save money.\n",
    "\n",
    "- `A3.` To embed the document in small chunks ( âœ… )\n",
    "\n",
    "- `A4.` To turn the words into tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 9` Why do we need to embed our documents?\n",
    "\n",
    "- `A1.` To spend less tokens and save money\n",
    "\n",
    "- `A2.` To turn words into tokens and perfom searches later\n",
    "\n",
    "- `A3.` To turn words into vectors and perform searches later ( âœ… )\n",
    "\n",
    "- `A4.` To spend less money and save tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“– `Question 10` Why do we use Vector Stores?\n",
    "\n",
    "- `A1.` To store embeddings\n",
    "\n",
    "- `A2.` To search embeddings\n",
    "\n",
    "- `A3.` To store and search embeddings ( âœ… )\n",
    "\n",
    "- `A4.` To turn documents into embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
