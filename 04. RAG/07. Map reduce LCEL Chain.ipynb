{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stuff는 질문을 query하여 관련있는 지문을 먼저 찾아서 찾은 지문 전체를 prompt로 넣고 llm을 돌린다.\n",
    "\n",
    "map reduce는 질문을 기반으로 retriever를 통해 찾은 질문과 연관된 지문 단락을 단락 수 만큼 for 문 수행하면서 \n",
    "\n",
    "각 단락 기준으로 llm 의 결과를 저장함.\n",
    "\n",
    "각각 저장된 llm의 결과를 prompt로 합쳐서 llm 이 최종 결과를 만들어 냄.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='성균관대를 합격한 학생들의 평균 내신은 2.63과 3.10입니다.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore('./.cache/')\n",
    "\n",
    "# Token 방식으로 텍스트를 인식\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",                 # 특정 기준으로 분할\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# UnstruturedFileLoader : 많은 파일들을 불러올 수 있음. docx, xlsx, pdf, ppt, txt 등 많은 파일들을 불러올 수 있는 Loader\n",
    "loader= UnstructuredFileLoader(\"./files/대입합불정리_세특포함_디랩.pdf\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)                                                                                                                                           \n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cacehd_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "# 캐시를 적용하여 임베딩\n",
    "# vectorstore = Chroma.from_documents(docs, cacehd_embeddings)\n",
    "vectorstore = FAISS.from_documents(docs, cacehd_embeddings)\n",
    "\n",
    "retriver = vectorstore.as_retriever()\n",
    "\n",
    "########### MAP REDUCE ###########\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    다음의 긴 Document의 일부 중, 질문에 대한 답변을 생성하는 것과 관련이 있는 부분을 찾아주세요.\n",
    "    관련이 있는 부분을 찾는다면, 해당 Text 를 그대로 반환해주세요.\n",
    "    ---\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs['documents']\n",
    "    question = inputs['question']\n",
    "\n",
    "    return \"\\n\\n\".join(map_doc_chain.invoke({\n",
    "        \"context\": doc.page_content,\n",
    "        \"question\": question,\n",
    "    }).content for doc in documents)\n",
    "\n",
    "map_chain = {\"documents\": retriver, \"question\": RunnablePassthrough()} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    주어진 긴 document의 발췌문들과 question을 통해, 최종 답변을 생성하세요. \n",
    "    ---\n",
    "    {context}\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = {\"context\": map_chain, \"question\": RunnablePassthrough()} | final_prompt | llm\n",
    "\n",
    "\n",
    "chain.invoke(\"성균관대를 합격자의 평균 내신등급은 어느 정도야 ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
